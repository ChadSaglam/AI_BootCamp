{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a97d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0feebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chadsglm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/chadsglm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure necessary NLTK data is downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8e7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
    "df = df[['v1', 'v2']]\n",
    "df.columns = ['label', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f567a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ffbb70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return [self._preprocess(text) for text in X]\n",
    "\n",
    "    def _preprocess(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "        text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "        text = nltk.word_tokenize(text)\n",
    "        text = [self.ps.stem(word) for word in text if word.isalnum() and word not in stopwords.words('english')]\n",
    "        return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74222c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for model\n",
    "X = df['text']\n",
    "y = df['label'].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba931e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb04208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model pipeline with custom transformer\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor()),\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    ('model', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6371dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {'model__alpha': [0.1, 0.5, 1.0, 5.0]}\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ed7ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd301d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8644e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model and vectorizer\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump((tfidf, model), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce9b450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d07d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_text = \"\"\"\n",
    "Hallo,\n",
    "\n",
    "Wären Sie daran interessiert, Ihr bestehendes Unternehmen mit einer neuen Website online zu stellen?\n",
    "\n",
    "Ich habe ein erfahrenes Website-Design-Team, das eine sehr professionelle Website erstellt, die sich wirklich einfacher selbst verwalten lässt.\n",
    "\n",
    "Ich bin sicher, dass Ihnen Ihre neue Homepage im modernen Design zu einem sehr erschwinglichen Preis gefällt.\n",
    "\n",
    "Ich würde mich sehr freuen, wenn Sie mir Ihre Idee oder Grundvoraussetzung für die Erstellung einer professionellen Website mitteilen könnten. Wir unterbreiten Ihnen dann einen kurzen Unternehmensvorschlag zu einem sehr erschwinglichen Preis.\n",
    "\n",
    "Mit freundlichen Grüßen,\n",
    "George\n",
    "\"\"\"\n",
    "\n",
    "# Assuming transform_text, tfidf, and model are already defined and loaded\n",
    "transformed_email = transform_text(email_text)\n",
    "vector_input = tfidf.transform([transformed_email])\n",
    "result = model.predict(vector_input)[0]\n",
    "\n",
    "print(\"Spam\" if result == 1 else \"Not Spam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e12d0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63e4cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd1479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

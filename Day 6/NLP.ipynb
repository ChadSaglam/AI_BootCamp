{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a4ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00db0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1005343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/chadsglm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac3fe439",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Yaylaya gitmisti yayla zamani, Gülizar döndü de döndü dönmedi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23666e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YAYLAYA GITMISTI YAYLA ZAMANI, GÜLIZAR DÖNDÜ DE DÖNDÜ DÖNMEDI'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab0b9019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yaylaya',\n",
       " 'gitmisti',\n",
       " 'yayla',\n",
       " 'zamani,',\n",
       " 'Gülizar',\n",
       " 'döndü',\n",
       " 'de',\n",
       " 'döndü',\n",
       " 'dönmedi']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29928726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize #Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6870238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"I love Python. Chad lives in a big city. Please call me back. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "152fda5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love Python', ' Chad lives in a big city', ' Please call me back', ' ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ed63609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love Python.', 'Chad lives in a big city.', 'Please call me back.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ecd0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize #Word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd9f9a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'love',\n",
       " 'Python',\n",
       " '.',\n",
       " 'Chad',\n",
       " 'lives',\n",
       " 'in',\n",
       " 'a',\n",
       " 'big',\n",
       " 'city',\n",
       " '.',\n",
       " 'Please',\n",
       " 'call',\n",
       " 'me',\n",
       " 'back',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e88a6",
   "metadata": {},
   "source": [
    "### Regular Expression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dd7cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fd4743d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'love',\n",
       " 'Python.',\n",
       " 'Chad',\n",
       " 'lives',\n",
       " 'in',\n",
       " 'a',\n",
       " 'big',\n",
       " 'city.',\n",
       " 'Please',\n",
       " 'call',\n",
       " 'me',\n",
       " 'back',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TreebankWordTokenizer().tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "133f01e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chadsglm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c523e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.stopwords.words(\"English\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a160f9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acaba', 'ama', 'aslında', 'az', 'bazı', 'belki', 'biri', 'birkaç', 'birşey', 'biz', 'bu', 'çok', 'çünkü', 'da', 'daha', 'de', 'defa', 'diye', 'eğer', 'en', 'gibi', 'hem', 'hep', 'hepsi', 'her', 'hiç', 'için', 'ile', 'ise', 'kez', 'ki', 'kim', 'mı', 'mu', 'mü', 'nasıl', 'ne', 'neden', 'nerde', 'nerede', 'nereye', 'niçin', 'niye', 'o', 'sanki', 'şey', 'siz', 'şu', 'tüm', 've', 'veya', 'ya', 'yani']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.stopwords.words(\"Turkish\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1db08c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6aff0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df337abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Don', \"'\", 't', 'hesitate', 'to', 'ask', 'questions']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.tokenize(\"Don't hesitate to ask questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aadbfff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import BlanklineTokenizer #Clean empty places in the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a956ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent='''\n",
    "Hello Sir\n",
    "\n",
    "I got 90 in the exam but I expected 100\n",
    "\n",
    "Best regards\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61101c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nHello Sir', 'I got 90 in the exam but I expected 100', 'Best regards']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BlanklineTokenizer().tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bf0469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "837f8e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=\"She secures 90.56% in class X. She is a meritorious student\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6478c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=RegexpTokenizer('[A-Z]\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "946eae2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['She', 'She']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.tokenize(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc6d3dc",
   "metadata": {},
   "source": [
    "### Stemma & Lemma : Removing affixes & finding roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d976712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e45cc006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happi'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PorterStemmer().stem(\"Happiness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd008c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3512eaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'talk'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.stem(\"talking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85b90a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['houses', 'trains', 'pens', 'cars', 'eaten', 'sick', 'nice', 'bought', 'selling', 'sized', 'speech',\n",
    "       'rolling', 'marching', 'identifications', 'universal', 'beautiful', 'references']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "846e3b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "affixes=[pr.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77986b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hous',\n",
       " 'train',\n",
       " 'pen',\n",
       " 'car',\n",
       " 'eaten',\n",
       " 'sick',\n",
       " 'nice',\n",
       " 'bought',\n",
       " 'sell',\n",
       " 'size',\n",
       " 'speech',\n",
       " 'roll',\n",
       " 'march',\n",
       " 'identif',\n",
       " 'univers',\n",
       " 'beauti',\n",
       " 'refer']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db0ff254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5f05867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LancasterStemmer().stem(\"Happiness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79882402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "328fd01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51c0159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27d5e02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'working'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.lemmatize('working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51c78b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part of Speech - POS Isim fiil, ozne yuklem, fiil fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76ab8c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.lemmatize('ran', pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef8013e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.lemmatize('is', pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d03bbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/chadsglm/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91157005",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=word_tokenize('it is a pleasant day today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57b6f2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('pleasant', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('today', 'NN')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0875abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2=word_tokenize(\"Zafer loves stuffed grape leaves. Artificial Intelligence is cool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36155418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Zafer', 'NNP'),\n",
       " ('loves', 'VBZ'),\n",
       " ('stuffed', 'JJ'),\n",
       " ('grape', 'NN'),\n",
       " ('leaves', 'VBZ'),\n",
       " ('.', '.'),\n",
       " ('Artificial', 'JJ'),\n",
       " ('Intelligence', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('cool', 'JJ')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b28ee810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d0154c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3777580e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell(\"tghe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1914dc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'my spelling is good'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell(\"my splllig is goad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d17e6ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e974e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d038f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=TextBlob(\"I havv goad splelig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0061681c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"I have good spelling\")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14173071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55d3df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72beb31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect(\"Ein, zwei, fünf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df88fcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tr'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect(\"başka merhaba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06d2c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob=TextBlob(\"I am a free black man from Afrika\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a40fd91d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextBlob' object has no attribute 'translate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m blob\u001b[38;5;241m.\u001b[39mtranslate(from_lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m, to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mde\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TextBlob' object has no attribute 'translate'"
     ]
    }
   ],
   "source": [
    "blob.translate(from_lang='en', to='de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"Hayat kisa, kuslar ucuyor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=TextBlob(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e70c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.translate(\"tr\",\"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8741ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markov Chain - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c2deb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3005424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs=RegexpStemmer('ing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ed6cc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Work'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.stem(\"Working\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3dc2ffe",
   "metadata": {},
   "source": [
    "# NLP Projesinde 7 Altin Kural\n",
    "1- Noktalama isaretleri Kaldirilmasi\n",
    "2- Hepsinin kucuk harfe cevrilmesi\n",
    "3- Enter veya \\n Kaldirilmasi\n",
    "4- Rakalmlarin kaldirilmasi\n",
    "5- Tokenize Etmek\n",
    "6- Eklerini kaldir, koklerini bul\n",
    "7- Stopword(gereksiz kelimeleri) Kaldir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0ee5035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "48f0ae1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SnowballStemmer.languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9158c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "spstemmer=SnowballStemmer(\"spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3d42add9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'com'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spstemmer.stem(\"comiendo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dd34c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install TurkishStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "11a376de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TurkishStemmer import TurkishStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9cc7857c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bardak'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TurkishStemmer().stem(\"bardaktan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fc021dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'göz'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TurkishStemmer().stem(\"gözde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "163c7257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import DefaultTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "24a2f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag=DefaultTagger(\"He is the man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a525dc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beautiful', 'He is the man'), ('morning', 'He is the man')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.tag([\"beautiful\", \"morning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ded04921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF = Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1af6af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "edfda1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e9029041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in search(\"Chad Saglam\", lang=\"tr\"):\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8af4b0",
   "metadata": {},
   "source": [
    "### Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dedefd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "20c48355",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\"Call you tonight\", \"Call me a cab\", \"Please call me back PLEASE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7cf94bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "86fa01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=pd.DataFrame(vect.fit_transform(x).toarray(),columns=vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "79dfe278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>back</th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   back  cab  call  me  please  tonight  you\n",
       "0     0    0     1   0       0        1    1\n",
       "1     0    1     1   1       0        0    0\n",
       "2     1    0     1   1       2        0    0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "93e4d44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect=CountVectorizer()\n",
    "df=vect.fit_transform(x).toarray().sum(axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "55d3f32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>back</th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   back  cab  call  me  please  tonight  you\n",
       "0     1    1     3   2       2        1    1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.reshape(1,7), columns=vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "07dad34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>back</th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   back  cab      call   me  please  tonight  you\n",
       "0   0.0  0.0  0.333333  0.0     0.0      1.0  1.0\n",
       "1   0.0  1.0  0.333333  0.5     0.0      0.0  0.0\n",
       "2   1.0  0.0  0.333333  0.5     1.0      0.0  0.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf/df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bea77d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "86177eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>back</th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.652491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.547832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.410747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242594</td>\n",
       "      <td>0.312384</td>\n",
       "      <td>0.821494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       back       cab      call        me    please   tonight       you\n",
       "0  0.000000  0.000000  0.385372  0.000000  0.000000  0.652491  0.652491\n",
       "1  0.000000  0.720333  0.425441  0.547832  0.000000  0.000000  0.000000\n",
       "2  0.410747  0.000000  0.242594  0.312384  0.821494  0.000000  0.000000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vect.fit_transform(x).toarray(),columns=vect.get_feature_names_out()) #Vectorun uzunlugunu hesap ediyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec48bdd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d3c04f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.8, subjectivity=0.9)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"I hate you\").sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "958d894e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.5, subjectivity=0.6)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"I love you\").sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "729e515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=1.0, subjectivity=0.3)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"You are the best\").sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc15ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
